{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "This is a companion notebook for the book [Deep Learning with Python, Second Edition](https://www.manning.com/books/deep-learning-with-python-second-edition?a_aid=keras&a_bid=76564dff). For readability, it only contains runnable code blocks and section titles, and omits everything else in the book: text paragraphs, figures, and pseudocode.\n",
    "\n",
    "**If you want to be able to follow what's going on, I recommend reading the notebook side by side with your copy of the book.**\n",
    "\n",
    "This notebook was generated for TensorFlow 2.6."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "# Fundamentals of machine learning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Generalization: The goal of machine learning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Underfitting and overfitting"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Noisy training data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Ambiguous features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Rare features and spurious correlations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Adding white-noise channels or all-zeros channels to MNIST**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "import numpy as np\n",
    "\n",
    "(train_images, train_labels), _ = mnist.load_data()\n",
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype(\"float32\") / 255\n",
    "\n",
    "train_images_with_noise_channels = np.concatenate(\n",
    "    [train_images, np.random.random((len(train_images), 784))], axis=1)\n",
    "\n",
    "train_images_with_zeros_channels = np.concatenate(\n",
    "    [train_images, np.zeros((len(train_images), 784))], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Training the same model on MNIST data with noise channels or all-zero channels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 0.6097 - accuracy: 0.8142 - val_loss: 0.4290 - val_accuracy: 0.8513\n",
      "Epoch 2/10\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.2553 - accuracy: 0.9219 - val_loss: 0.2426 - val_accuracy: 0.9229\n",
      "Epoch 3/10\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.1676 - accuracy: 0.9491 - val_loss: 0.1667 - val_accuracy: 0.9471\n",
      "Epoch 4/10\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.1192 - accuracy: 0.9630 - val_loss: 0.1678 - val_accuracy: 0.9502\n",
      "Epoch 5/10\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0886 - accuracy: 0.9722 - val_loss: 0.1230 - val_accuracy: 0.9649\n",
      "Epoch 6/10\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0628 - accuracy: 0.9799 - val_loss: 0.1165 - val_accuracy: 0.9685\n",
      "Epoch 7/10\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0462 - accuracy: 0.9851 - val_loss: 0.1349 - val_accuracy: 0.9631\n",
      "Epoch 8/10\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0332 - accuracy: 0.9895 - val_loss: 0.1802 - val_accuracy: 0.9556\n",
      "Epoch 9/10\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0249 - accuracy: 0.9926 - val_loss: 0.1338 - val_accuracy: 0.9652\n",
      "Epoch 10/10\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0179 - accuracy: 0.9945 - val_loss: 0.1240 - val_accuracy: 0.9701\n",
      "Epoch 1/10\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.2969 - accuracy: 0.9141 - val_loss: 0.1542 - val_accuracy: 0.9567\n",
      "Epoch 2/10\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.1225 - accuracy: 0.9638 - val_loss: 0.1036 - val_accuracy: 0.9688\n",
      "Epoch 3/10\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0809 - accuracy: 0.9764 - val_loss: 0.1028 - val_accuracy: 0.9672\n",
      "Epoch 4/10\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0580 - accuracy: 0.9827 - val_loss: 0.0825 - val_accuracy: 0.9743\n",
      "Epoch 5/10\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0427 - accuracy: 0.9875 - val_loss: 0.0786 - val_accuracy: 0.9761\n",
      "Epoch 6/10\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0327 - accuracy: 0.9906 - val_loss: 0.0757 - val_accuracy: 0.9778\n",
      "Epoch 7/10\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0244 - accuracy: 0.9932 - val_loss: 0.0756 - val_accuracy: 0.9787\n",
      "Epoch 8/10\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0183 - accuracy: 0.9955 - val_loss: 0.0787 - val_accuracy: 0.9789\n",
      "Epoch 9/10\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0142 - accuracy: 0.9962 - val_loss: 0.0734 - val_accuracy: 0.9804\n",
      "Epoch 10/10\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0105 - accuracy: 0.9975 - val_loss: 0.0757 - val_accuracy: 0.9803\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def get_model():\n",
    "    # Create a simple model\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(512, activation=\"relu\"),\n",
    "        layers.Dense(10, activation=\"softmax\")\n",
    "    ])\n",
    "    model.compile(optimizer=\"rmsprop\",\n",
    "                  loss=\"sparse_categorical_crossentropy\",\n",
    "                  metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "model = get_model()\n",
    "history_noise = model.fit(\n",
    "    train_images_with_noise_channels, train_labels,\n",
    "    epochs=10,\n",
    "    batch_size=128,\n",
    "    validation_split=0.2)\n",
    "\n",
    "model = get_model()\n",
    "history_zeros = model.fit(\n",
    "    train_images_with_zeros_channels, train_labels,\n",
    "    epochs=10,\n",
    "    batch_size=128,\n",
    "    validation_split=0.2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Plotting a validation accuracy comparison**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2509f898820>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "val_acc_noise = history_noise.history[\"val_accuracy\"]\n",
    "val_acc_zeros = history_zeros.history[\"val_accuracy\"]\n",
    "epochs = range(1, 11)\n",
    "plt.plot(epochs, val_acc_noise, \"b-\",\n",
    "         label=\"Validation accuracy with noise channels\")\n",
    "plt.plot(epochs, val_acc_zeros, \"b--\",\n",
    "         label=\"Validation accuracy with zeros channels\")\n",
    "plt.title(\"Effect of noise channels on validation accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "# 在深度学习中，画图对比不同方案的差异很重要"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### The nature of generalization in deep learning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Fitting a MNIST model with randomly shuffled labels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "375/375 [==============================] - 3s 6ms/step - loss: 2.3160 - accuracy: 0.1018 - val_loss: 2.3069 - val_accuracy: 0.1058\n",
      "Epoch 2/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.2995 - accuracy: 0.1181 - val_loss: 2.3122 - val_accuracy: 0.1035\n",
      "Epoch 3/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.2911 - accuracy: 0.1264 - val_loss: 2.3251 - val_accuracy: 0.1057\n",
      "Epoch 4/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.2794 - accuracy: 0.1401 - val_loss: 2.3212 - val_accuracy: 0.1067\n",
      "Epoch 5/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.2639 - accuracy: 0.1525 - val_loss: 2.3405 - val_accuracy: 0.1039\n",
      "Epoch 6/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.2449 - accuracy: 0.1674 - val_loss: 2.3527 - val_accuracy: 0.0995\n",
      "Epoch 7/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.2217 - accuracy: 0.1796 - val_loss: 2.3669 - val_accuracy: 0.1018\n",
      "Epoch 8/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.1959 - accuracy: 0.1957 - val_loss: 2.3775 - val_accuracy: 0.1003\n",
      "Epoch 9/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.1655 - accuracy: 0.2141 - val_loss: 2.3950 - val_accuracy: 0.1026\n",
      "Epoch 10/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.1350 - accuracy: 0.2262 - val_loss: 2.4147 - val_accuracy: 0.1039\n",
      "Epoch 11/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.0993 - accuracy: 0.2469 - val_loss: 2.4462 - val_accuracy: 0.1054\n",
      "Epoch 12/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.0645 - accuracy: 0.2638 - val_loss: 2.4718 - val_accuracy: 0.1018\n",
      "Epoch 13/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.0284 - accuracy: 0.2770 - val_loss: 2.4937 - val_accuracy: 0.1005\n",
      "Epoch 14/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.9910 - accuracy: 0.2932 - val_loss: 2.5114 - val_accuracy: 0.1041\n",
      "Epoch 15/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.9537 - accuracy: 0.3110 - val_loss: 2.5494 - val_accuracy: 0.1022\n",
      "Epoch 16/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.9163 - accuracy: 0.3266 - val_loss: 2.5962 - val_accuracy: 0.0978\n",
      "Epoch 17/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 1.8761 - accuracy: 0.3415 - val_loss: 2.6173 - val_accuracy: 0.1013\n",
      "Epoch 18/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.8367 - accuracy: 0.3568 - val_loss: 2.6590 - val_accuracy: 0.1010\n",
      "Epoch 19/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.7983 - accuracy: 0.3727 - val_loss: 2.6915 - val_accuracy: 0.1013\n",
      "Epoch 20/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 1.7605 - accuracy: 0.3877 - val_loss: 2.7238 - val_accuracy: 0.1032\n",
      "Epoch 21/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.7237 - accuracy: 0.4052 - val_loss: 2.7714 - val_accuracy: 0.0998\n",
      "Epoch 22/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 1.6874 - accuracy: 0.4155 - val_loss: 2.8319 - val_accuracy: 0.0997\n",
      "Epoch 23/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 1.6489 - accuracy: 0.4316 - val_loss: 2.8743 - val_accuracy: 0.1047\n",
      "Epoch 24/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.6147 - accuracy: 0.4417 - val_loss: 2.9000 - val_accuracy: 0.1015\n",
      "Epoch 25/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 1.5791 - accuracy: 0.4583 - val_loss: 2.9519 - val_accuracy: 0.0988\n",
      "Epoch 26/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.5446 - accuracy: 0.4692 - val_loss: 2.9980 - val_accuracy: 0.1018\n",
      "Epoch 27/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 1.5110 - accuracy: 0.4851 - val_loss: 3.0401 - val_accuracy: 0.1010\n",
      "Epoch 28/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 1.4792 - accuracy: 0.4951 - val_loss: 3.0964 - val_accuracy: 0.1020\n",
      "Epoch 29/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 1.4477 - accuracy: 0.5056 - val_loss: 3.1390 - val_accuracy: 0.1018\n",
      "Epoch 30/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 1.4173 - accuracy: 0.5186 - val_loss: 3.2035 - val_accuracy: 0.1007\n",
      "Epoch 31/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 1.3865 - accuracy: 0.5288 - val_loss: 3.2356 - val_accuracy: 0.0984\n",
      "Epoch 32/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 1.3570 - accuracy: 0.5400 - val_loss: 3.2787 - val_accuracy: 0.1009\n",
      "Epoch 33/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 1.3272 - accuracy: 0.5494 - val_loss: 3.3429 - val_accuracy: 0.0967\n",
      "Epoch 34/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 1.2997 - accuracy: 0.5616 - val_loss: 3.3997 - val_accuracy: 0.1001\n",
      "Epoch 35/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 1.2695 - accuracy: 0.5716 - val_loss: 3.4542 - val_accuracy: 0.1067\n",
      "Epoch 36/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 1.2433 - accuracy: 0.5810 - val_loss: 3.5272 - val_accuracy: 0.0976\n",
      "Epoch 37/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 1.2189 - accuracy: 0.5904 - val_loss: 3.5633 - val_accuracy: 0.1028\n",
      "Epoch 38/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 1.1929 - accuracy: 0.6008 - val_loss: 3.6437 - val_accuracy: 0.0990\n",
      "Epoch 39/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 1.1658 - accuracy: 0.6082 - val_loss: 3.6947 - val_accuracy: 0.1023\n",
      "Epoch 40/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 1.1402 - accuracy: 0.6186 - val_loss: 3.8305 - val_accuracy: 0.1011\n",
      "Epoch 41/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 1.1167 - accuracy: 0.6277 - val_loss: 3.8308 - val_accuracy: 0.0984\n",
      "Epoch 42/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 1.0947 - accuracy: 0.6348 - val_loss: 3.8873 - val_accuracy: 0.0986\n",
      "Epoch 43/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 1.0698 - accuracy: 0.6444 - val_loss: 3.9410 - val_accuracy: 0.0975\n",
      "Epoch 44/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 1.0481 - accuracy: 0.6521 - val_loss: 4.0086 - val_accuracy: 0.1013\n",
      "Epoch 45/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 1.0276 - accuracy: 0.6578 - val_loss: 4.0519 - val_accuracy: 0.0977\n",
      "Epoch 46/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 1.0048 - accuracy: 0.6666 - val_loss: 4.1410 - val_accuracy: 0.0996\n",
      "Epoch 47/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.9854 - accuracy: 0.6724 - val_loss: 4.2089 - val_accuracy: 0.0982\n",
      "Epoch 48/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.9628 - accuracy: 0.6815 - val_loss: 4.2479 - val_accuracy: 0.0962\n",
      "Epoch 49/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.9445 - accuracy: 0.6884 - val_loss: 4.3219 - val_accuracy: 0.0985\n",
      "Epoch 50/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.9232 - accuracy: 0.6979 - val_loss: 4.3751 - val_accuracy: 0.1002\n",
      "Epoch 51/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.9045 - accuracy: 0.7007 - val_loss: 4.4760 - val_accuracy: 0.0976\n",
      "Epoch 52/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.8875 - accuracy: 0.7101 - val_loss: 4.5888 - val_accuracy: 0.0981\n",
      "Epoch 53/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.8692 - accuracy: 0.7134 - val_loss: 4.5529 - val_accuracy: 0.0983\n",
      "Epoch 54/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.8501 - accuracy: 0.7213 - val_loss: 4.6544 - val_accuracy: 0.0983\n",
      "Epoch 55/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.8339 - accuracy: 0.7283 - val_loss: 4.7432 - val_accuracy: 0.0981\n",
      "Epoch 56/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.8157 - accuracy: 0.7335 - val_loss: 4.7759 - val_accuracy: 0.0964\n",
      "Epoch 57/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.7990 - accuracy: 0.7412 - val_loss: 4.8298 - val_accuracy: 0.0986\n",
      "Epoch 58/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.7838 - accuracy: 0.7434 - val_loss: 4.9407 - val_accuracy: 0.0990\n",
      "Epoch 59/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.7678 - accuracy: 0.7491 - val_loss: 5.0263 - val_accuracy: 0.0983\n",
      "Epoch 60/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.7524 - accuracy: 0.7568 - val_loss: 5.0562 - val_accuracy: 0.0953\n",
      "Epoch 61/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.7377 - accuracy: 0.7615 - val_loss: 5.1032 - val_accuracy: 0.0998\n",
      "Epoch 62/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.7227 - accuracy: 0.7658 - val_loss: 5.1878 - val_accuracy: 0.1037\n",
      "Epoch 63/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.7082 - accuracy: 0.7723 - val_loss: 5.2717 - val_accuracy: 0.0979\n",
      "Epoch 64/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.6920 - accuracy: 0.7782 - val_loss: 5.3514 - val_accuracy: 0.0979\n",
      "Epoch 65/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.6806 - accuracy: 0.7809 - val_loss: 5.4391 - val_accuracy: 0.0981\n",
      "Epoch 66/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.6681 - accuracy: 0.7853 - val_loss: 5.4720 - val_accuracy: 0.0998\n",
      "Epoch 67/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.6543 - accuracy: 0.7901 - val_loss: 5.5562 - val_accuracy: 0.0986\n",
      "Epoch 68/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.6407 - accuracy: 0.7921 - val_loss: 5.6719 - val_accuracy: 0.0973\n",
      "Epoch 69/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.6272 - accuracy: 0.7997 - val_loss: 5.7195 - val_accuracy: 0.0986\n",
      "Epoch 70/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.6164 - accuracy: 0.8025 - val_loss: 5.7677 - val_accuracy: 0.0999\n",
      "Epoch 71/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.6046 - accuracy: 0.8065 - val_loss: 5.8881 - val_accuracy: 0.0958\n",
      "Epoch 72/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.5928 - accuracy: 0.8100 - val_loss: 5.9150 - val_accuracy: 0.0992\n",
      "Epoch 73/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.5818 - accuracy: 0.8158 - val_loss: 5.9665 - val_accuracy: 0.1003\n",
      "Epoch 74/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.5699 - accuracy: 0.8195 - val_loss: 6.0742 - val_accuracy: 0.0968\n",
      "Epoch 75/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.5597 - accuracy: 0.8227 - val_loss: 6.1770 - val_accuracy: 0.0974\n",
      "Epoch 76/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.5507 - accuracy: 0.8255 - val_loss: 6.2346 - val_accuracy: 0.0978\n",
      "Epoch 77/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.5377 - accuracy: 0.8292 - val_loss: 6.3040 - val_accuracy: 0.0967\n",
      "Epoch 78/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.5282 - accuracy: 0.8328 - val_loss: 6.3645 - val_accuracy: 0.0979\n",
      "Epoch 79/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.5182 - accuracy: 0.8358 - val_loss: 6.4443 - val_accuracy: 0.0978\n",
      "Epoch 80/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.5079 - accuracy: 0.8397 - val_loss: 6.5255 - val_accuracy: 0.1005\n",
      "Epoch 81/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.4996 - accuracy: 0.8427 - val_loss: 6.5881 - val_accuracy: 0.0997\n",
      "Epoch 82/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.4897 - accuracy: 0.8470 - val_loss: 6.6593 - val_accuracy: 0.0963\n",
      "Epoch 83/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.4823 - accuracy: 0.8487 - val_loss: 6.7175 - val_accuracy: 0.0982\n",
      "Epoch 84/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.4732 - accuracy: 0.8501 - val_loss: 6.8184 - val_accuracy: 0.0983\n",
      "Epoch 85/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4619 - accuracy: 0.8559 - val_loss: 6.9090 - val_accuracy: 0.0999\n",
      "Epoch 86/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.4546 - accuracy: 0.8573 - val_loss: 6.9711 - val_accuracy: 0.0971\n",
      "Epoch 87/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.4452 - accuracy: 0.8601 - val_loss: 7.0356 - val_accuracy: 0.0962\n",
      "Epoch 88/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.4378 - accuracy: 0.8623 - val_loss: 7.1934 - val_accuracy: 0.0983\n",
      "Epoch 89/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4286 - accuracy: 0.8662 - val_loss: 7.1712 - val_accuracy: 0.0984\n",
      "Epoch 90/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4215 - accuracy: 0.8679 - val_loss: 7.2566 - val_accuracy: 0.0958\n",
      "Epoch 91/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4124 - accuracy: 0.8716 - val_loss: 7.3451 - val_accuracy: 0.0983\n",
      "Epoch 92/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4073 - accuracy: 0.8714 - val_loss: 7.4023 - val_accuracy: 0.0979\n",
      "Epoch 93/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.3998 - accuracy: 0.8763 - val_loss: 7.4798 - val_accuracy: 0.0970\n",
      "Epoch 94/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.3916 - accuracy: 0.8789 - val_loss: 7.5783 - val_accuracy: 0.0998\n",
      "Epoch 95/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.3858 - accuracy: 0.8807 - val_loss: 7.6448 - val_accuracy: 0.1000\n",
      "Epoch 96/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.3771 - accuracy: 0.8830 - val_loss: 7.7730 - val_accuracy: 0.0986\n",
      "Epoch 97/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.3716 - accuracy: 0.8839 - val_loss: 7.8240 - val_accuracy: 0.1003\n",
      "Epoch 98/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.3637 - accuracy: 0.8880 - val_loss: 7.8570 - val_accuracy: 0.0988\n",
      "Epoch 99/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.3593 - accuracy: 0.8889 - val_loss: 8.0003 - val_accuracy: 0.1000\n",
      "Epoch 100/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.3523 - accuracy: 0.8923 - val_loss: 8.0031 - val_accuracy: 0.0965\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2508000d940>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_images, train_labels), _ = mnist.load_data()\n",
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype(\"float32\") / 255\n",
    "\n",
    "random_train_labels = train_labels[:]\n",
    "np.random.shuffle(random_train_labels)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(512, activation=\"relu\"),\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_images, random_train_labels,\n",
    "          epochs=100,\n",
    "          batch_size=128,\n",
    "          validation_split=0.2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### The manifold hypothesis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Interpolation as a source of generalization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Why deep learning works"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Training data is paramount"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Evaluating machine-learning models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Training, validation, and test sets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Simple hold-out validation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### K-fold validation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Iterated K-fold validation with shuffling"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Beating a common-sense baseline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Things to keep in mind about model evaluation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Improving model fit"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Tuning key gradient descent parameters"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Training a MNIST model with an incorrectly high learning rate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 478.0742 - accuracy: 0.2690 - val_loss: 2.3550 - val_accuracy: 0.1638\n",
      "Epoch 2/10\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.4967 - accuracy: 0.1526 - val_loss: 2.6023 - val_accuracy: 0.1061\n",
      "Epoch 3/10\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.5026 - accuracy: 0.1489 - val_loss: 2.4925 - val_accuracy: 0.1797\n",
      "Epoch 4/10\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3858 - accuracy: 0.1608 - val_loss: 2.1698 - val_accuracy: 0.1717\n",
      "Epoch 5/10\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.4035 - accuracy: 0.1662 - val_loss: 2.3924 - val_accuracy: 0.1922\n",
      "Epoch 6/10\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3999 - accuracy: 0.1785 - val_loss: 2.4515 - val_accuracy: 0.1860\n",
      "Epoch 7/10\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.4773 - accuracy: 0.1860 - val_loss: 2.1937 - val_accuracy: 0.1928\n",
      "Epoch 8/10\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.4568 - accuracy: 0.1772 - val_loss: 2.1575 - val_accuracy: 0.1787\n",
      "Epoch 9/10\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.4412 - accuracy: 0.1777 - val_loss: 2.3087 - val_accuracy: 0.1869\n",
      "Epoch 10/10\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.2637 - accuracy: 0.1842 - val_loss: 2.1361 - val_accuracy: 0.1998\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2508276fd30>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_images, train_labels), _ = mnist.load_data()\n",
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype(\"float32\") / 255\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(512, activation=\"relu\"),\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(optimizer=keras.optimizers.RMSprop(1.), # 学习率为 1.0\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=10,\n",
    "          batch_size=128,\n",
    "          validation_split=0.2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**The same model with a more appropriate learning rate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "375/375 [==============================] - 3s 6ms/step - loss: 0.3521 - accuracy: 0.9104 - val_loss: 0.1409 - val_accuracy: 0.9625\n",
      "Epoch 2/10\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.1256 - accuracy: 0.9653 - val_loss: 0.1547 - val_accuracy: 0.9604\n",
      "Epoch 3/10\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0987 - accuracy: 0.9736 - val_loss: 0.1520 - val_accuracy: 0.9653\n",
      "Epoch 4/10\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0835 - accuracy: 0.9791 - val_loss: 0.1511 - val_accuracy: 0.9691\n",
      "Epoch 5/10\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0725 - accuracy: 0.9825 - val_loss: 0.2262 - val_accuracy: 0.9627\n",
      "Epoch 6/10\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0674 - accuracy: 0.9846 - val_loss: 0.2053 - val_accuracy: 0.9672\n",
      "Epoch 7/10\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0540 - accuracy: 0.9870 - val_loss: 0.2005 - val_accuracy: 0.9721\n",
      "Epoch 8/10\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0484 - accuracy: 0.9883 - val_loss: 0.1962 - val_accuracy: 0.9732\n",
      "Epoch 9/10\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0403 - accuracy: 0.9906 - val_loss: 0.2045 - val_accuracy: 0.9741\n",
      "Epoch 10/10\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0378 - accuracy: 0.9916 - val_loss: 0.2345 - val_accuracy: 0.9733\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x250834f0400>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(512, activation=\"relu\"),\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(optimizer=keras.optimizers.RMSprop(1e-2), # 学习率为 0.01\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=10,\n",
    "          batch_size=128,\n",
    "          validation_split=0.2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Leveraging better architecture priors"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Increasing model capacity"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**A simple logistic regression on MNIST**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.6700 - accuracy: 0.8326 - val_loss: 0.3615 - val_accuracy: 0.9033\n",
      "Epoch 2/20\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.3551 - accuracy: 0.9024 - val_loss: 0.3089 - val_accuracy: 0.9131\n",
      "Epoch 3/20\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.3185 - accuracy: 0.9110 - val_loss: 0.2938 - val_accuracy: 0.9180\n",
      "Epoch 4/20\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.3020 - accuracy: 0.9158 - val_loss: 0.2825 - val_accuracy: 0.9209\n",
      "Epoch 5/20\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.2924 - accuracy: 0.9187 - val_loss: 0.2784 - val_accuracy: 0.9232\n",
      "Epoch 6/20\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.2859 - accuracy: 0.9196 - val_loss: 0.2744 - val_accuracy: 0.9243\n",
      "Epoch 7/20\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.2807 - accuracy: 0.9218 - val_loss: 0.2713 - val_accuracy: 0.9265\n",
      "Epoch 8/20\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.2768 - accuracy: 0.9226 - val_loss: 0.2692 - val_accuracy: 0.9287\n",
      "Epoch 9/20\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.2735 - accuracy: 0.9238 - val_loss: 0.2669 - val_accuracy: 0.9284\n",
      "Epoch 10/20\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.2707 - accuracy: 0.9250 - val_loss: 0.2650 - val_accuracy: 0.9284\n",
      "Epoch 11/20\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.2687 - accuracy: 0.9250 - val_loss: 0.2669 - val_accuracy: 0.9286\n",
      "Epoch 12/20\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.2664 - accuracy: 0.9256 - val_loss: 0.2642 - val_accuracy: 0.9287\n",
      "Epoch 13/20\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.2648 - accuracy: 0.9272 - val_loss: 0.2655 - val_accuracy: 0.9273\n",
      "Epoch 14/20\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.2633 - accuracy: 0.9271 - val_loss: 0.2633 - val_accuracy: 0.9293\n",
      "Epoch 15/20\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.2618 - accuracy: 0.9277 - val_loss: 0.2646 - val_accuracy: 0.9285\n",
      "Epoch 16/20\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.2606 - accuracy: 0.9285 - val_loss: 0.2628 - val_accuracy: 0.9296\n",
      "Epoch 17/20\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.2594 - accuracy: 0.9286 - val_loss: 0.2631 - val_accuracy: 0.9298\n",
      "Epoch 18/20\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.2582 - accuracy: 0.9287 - val_loss: 0.2623 - val_accuracy: 0.9303\n",
      "Epoch 19/20\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.2570 - accuracy: 0.9298 - val_loss: 0.2615 - val_accuracy: 0.9296\n",
      "Epoch 20/20\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.2565 - accuracy: 0.9297 - val_loss: 0.2642 - val_accuracy: 0.9297\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([layers.Dense(10, activation=\"softmax\")])\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "history_small_model = model.fit(\n",
    "    train_images, train_labels,\n",
    "    epochs=20,\n",
    "    batch_size=128,\n",
    "    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x25080c53d60>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "val_loss = history_small_model.history[\"val_loss\"]\n",
    "epochs = range(1, 21)\n",
    "plt.plot(epochs, val_loss, \"b--\",\n",
    "         label=\"Validation loss\")\n",
    "plt.title(\"Effect of insufficient model capacity on validation loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3733 - accuracy: 0.8943 - val_loss: 0.1825 - val_accuracy: 0.9490\n",
      "Epoch 2/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1704 - accuracy: 0.9506 - val_loss: 0.1481 - val_accuracy: 0.9551\n",
      "Epoch 3/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1235 - accuracy: 0.9637 - val_loss: 0.1242 - val_accuracy: 0.9622\n",
      "Epoch 4/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0940 - accuracy: 0.9722 - val_loss: 0.1115 - val_accuracy: 0.9676\n",
      "Epoch 5/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0755 - accuracy: 0.9770 - val_loss: 0.0992 - val_accuracy: 0.9689\n",
      "Epoch 6/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0611 - accuracy: 0.9809 - val_loss: 0.0929 - val_accuracy: 0.9719\n",
      "Epoch 7/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0506 - accuracy: 0.9848 - val_loss: 0.0940 - val_accuracy: 0.9718\n",
      "Epoch 8/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0421 - accuracy: 0.9874 - val_loss: 0.0929 - val_accuracy: 0.9736\n",
      "Epoch 9/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0349 - accuracy: 0.9894 - val_loss: 0.0946 - val_accuracy: 0.9756\n",
      "Epoch 10/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0292 - accuracy: 0.9906 - val_loss: 0.0938 - val_accuracy: 0.9748\n",
      "Epoch 11/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0243 - accuracy: 0.9923 - val_loss: 0.1014 - val_accuracy: 0.9746\n",
      "Epoch 12/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0211 - accuracy: 0.9935 - val_loss: 0.1002 - val_accuracy: 0.9768\n",
      "Epoch 13/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0174 - accuracy: 0.9948 - val_loss: 0.1102 - val_accuracy: 0.9751\n",
      "Epoch 14/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0143 - accuracy: 0.9960 - val_loss: 0.1029 - val_accuracy: 0.9769\n",
      "Epoch 15/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0127 - accuracy: 0.9961 - val_loss: 0.1094 - val_accuracy: 0.9762\n",
      "Epoch 16/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0101 - accuracy: 0.9973 - val_loss: 0.1231 - val_accuracy: 0.9743\n",
      "Epoch 17/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0096 - accuracy: 0.9970 - val_loss: 0.1193 - val_accuracy: 0.9743\n",
      "Epoch 18/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0081 - accuracy: 0.9971 - val_loss: 0.1204 - val_accuracy: 0.9737\n",
      "Epoch 19/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0066 - accuracy: 0.9982 - val_loss: 0.1229 - val_accuracy: 0.9760\n",
      "Epoch 20/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0061 - accuracy: 0.9982 - val_loss: 0.1212 - val_accuracy: 0.9753\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(96, activation=\"relu\"),\n",
    "    layers.Dense(96, activation=\"relu\"),\n",
    "    layers.Dense(10, activation=\"softmax\"),\n",
    "])\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "history_large_model = model.fit(\n",
    "    train_images, train_labels,\n",
    "    epochs=20,\n",
    "    batch_size=128,\n",
    "    validation_split=0.2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Improving generalization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Dataset curation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Feature engineering"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Using early stopping"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Regularizing your model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Reducing the network's size"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Original model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30/30 [==============================] - 1s 28ms/step - loss: 0.5391 - accuracy: 0.7561 - val_loss: 0.4062 - val_accuracy: 0.8677\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.3246 - accuracy: 0.8963 - val_loss: 0.3080 - val_accuracy: 0.8875\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.2401 - accuracy: 0.9194 - val_loss: 0.2872 - val_accuracy: 0.8875\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.1935 - accuracy: 0.9368 - val_loss: 0.3058 - val_accuracy: 0.8766\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.1617 - accuracy: 0.9462 - val_loss: 0.2811 - val_accuracy: 0.8891\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.1386 - accuracy: 0.9552 - val_loss: 0.3036 - val_accuracy: 0.8818\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.1159 - accuracy: 0.9643 - val_loss: 0.3046 - val_accuracy: 0.8849\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.0983 - accuracy: 0.9711 - val_loss: 0.3183 - val_accuracy: 0.8829\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.0841 - accuracy: 0.9769 - val_loss: 0.3401 - val_accuracy: 0.8796\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 0s 17ms/step - loss: 0.0742 - accuracy: 0.9801 - val_loss: 0.3481 - val_accuracy: 0.8796\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.0601 - accuracy: 0.9859 - val_loss: 0.3782 - val_accuracy: 0.8769\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0544 - accuracy: 0.9857 - val_loss: 0.3928 - val_accuracy: 0.8785\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.0433 - accuracy: 0.9899 - val_loss: 0.4157 - val_accuracy: 0.8763\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.0372 - accuracy: 0.9922 - val_loss: 0.4324 - val_accuracy: 0.8745\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 0s 17ms/step - loss: 0.0315 - accuracy: 0.9945 - val_loss: 0.4584 - val_accuracy: 0.8736\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.0268 - accuracy: 0.9949 - val_loss: 0.4882 - val_accuracy: 0.8745\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.0231 - accuracy: 0.9952 - val_loss: 0.5042 - val_accuracy: 0.8707\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.0221 - accuracy: 0.9952 - val_loss: 0.5296 - val_accuracy: 0.8723\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0125 - accuracy: 0.9990 - val_loss: 0.5506 - val_accuracy: 0.8710\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0163 - accuracy: 0.9969 - val_loss: 0.5683 - val_accuracy: 0.8716\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import imdb\n",
    "(train_data, train_labels), _ = imdb.load_data(num_words=10000)\n",
    "\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1.\n",
    "    return results\n",
    "train_data = vectorize_sequences(train_data)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(16, activation=\"relu\"),\n",
    "    layers.Dense(16, activation=\"relu\"),\n",
    "    layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "history_original = model.fit(train_data, train_labels,\n",
    "                             epochs=20, batch_size=512, validation_split=0.4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Version of the model with lower capacity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30/30 [==============================] - 1s 23ms/step - loss: 0.6459 - accuracy: 0.7031 - val_loss: 0.5992 - val_accuracy: 0.7725\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 1s 18ms/step - loss: 0.5542 - accuracy: 0.8371 - val_loss: 0.5216 - val_accuracy: 0.8603\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.4708 - accuracy: 0.8801 - val_loss: 0.4509 - val_accuracy: 0.8714\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.3995 - accuracy: 0.8949 - val_loss: 0.3971 - val_accuracy: 0.8750\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.3426 - accuracy: 0.9053 - val_loss: 0.3568 - val_accuracy: 0.8811\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.2977 - accuracy: 0.9135 - val_loss: 0.3258 - val_accuracy: 0.8848\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 0s 17ms/step - loss: 0.2625 - accuracy: 0.9216 - val_loss: 0.3065 - val_accuracy: 0.8849\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.2347 - accuracy: 0.9281 - val_loss: 0.2921 - val_accuracy: 0.8891\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.2117 - accuracy: 0.9337 - val_loss: 0.2822 - val_accuracy: 0.8903\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.1927 - accuracy: 0.9398 - val_loss: 0.2777 - val_accuracy: 0.8917\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.1770 - accuracy: 0.9449 - val_loss: 0.2757 - val_accuracy: 0.8891\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 0s 17ms/step - loss: 0.1633 - accuracy: 0.9505 - val_loss: 0.2756 - val_accuracy: 0.8897\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.1510 - accuracy: 0.9538 - val_loss: 0.2766 - val_accuracy: 0.8901\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.1396 - accuracy: 0.9589 - val_loss: 0.2779 - val_accuracy: 0.8891\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.1290 - accuracy: 0.9627 - val_loss: 0.2865 - val_accuracy: 0.8865\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.1199 - accuracy: 0.9659 - val_loss: 0.2897 - val_accuracy: 0.8881\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.1118 - accuracy: 0.9689 - val_loss: 0.2912 - val_accuracy: 0.8859\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.1035 - accuracy: 0.9715 - val_loss: 0.3046 - val_accuracy: 0.8852\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.0961 - accuracy: 0.9737 - val_loss: 0.3051 - val_accuracy: 0.8850\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.0894 - accuracy: 0.9767 - val_loss: 0.3134 - val_accuracy: 0.8850\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(4, activation=\"relu\"),\n",
    "    layers.Dense(4, activation=\"relu\"),\n",
    "    layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "history_smaller_model = model.fit(\n",
    "    train_data, train_labels,\n",
    "    epochs=20, batch_size=512, validation_split=0.4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Version of the model with higher capacity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30/30 [==============================] - 3s 93ms/step - loss: 0.5901 - accuracy: 0.7088 - val_loss: 0.3671 - val_accuracy: 0.8595\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 2s 84ms/step - loss: 0.3256 - accuracy: 0.8689 - val_loss: 0.4409 - val_accuracy: 0.8057\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 2s 83ms/step - loss: 0.2502 - accuracy: 0.9006 - val_loss: 0.2864 - val_accuracy: 0.8796\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 2s 83ms/step - loss: 0.1825 - accuracy: 0.9287 - val_loss: 0.3208 - val_accuracy: 0.8727\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 2s 81ms/step - loss: 0.1542 - accuracy: 0.9395 - val_loss: 0.2815 - val_accuracy: 0.8867\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 2s 81ms/step - loss: 0.1044 - accuracy: 0.9636 - val_loss: 0.3234 - val_accuracy: 0.8870\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 2s 81ms/step - loss: 0.0870 - accuracy: 0.9702 - val_loss: 0.3556 - val_accuracy: 0.8851\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 2s 81ms/step - loss: 0.0879 - accuracy: 0.9733 - val_loss: 0.3526 - val_accuracy: 0.8826\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 2s 82ms/step - loss: 0.0615 - accuracy: 0.9809 - val_loss: 0.3241 - val_accuracy: 0.8808\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 3s 86ms/step - loss: 0.0131 - accuracy: 0.9990 - val_loss: 0.4672 - val_accuracy: 0.8808\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 3s 85ms/step - loss: 0.0813 - accuracy: 0.9823 - val_loss: 0.3976 - val_accuracy: 0.8816\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 2s 83ms/step - loss: 0.0056 - accuracy: 0.9996 - val_loss: 0.4981 - val_accuracy: 0.8815\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 2s 84ms/step - loss: 0.0026 - accuracy: 0.9997 - val_loss: 0.5621 - val_accuracy: 0.8809\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 3s 88ms/step - loss: 0.0690 - accuracy: 0.9881 - val_loss: 0.5376 - val_accuracy: 0.8616\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 3s 87ms/step - loss: 0.0048 - accuracy: 0.9998 - val_loss: 0.5186 - val_accuracy: 0.8822\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 3s 84ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.5929 - val_accuracy: 0.8823\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 2s 83ms/step - loss: 7.8311e-04 - accuracy: 1.0000 - val_loss: 0.6393 - val_accuracy: 0.8807\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 3s 84ms/step - loss: 4.8796e-04 - accuracy: 1.0000 - val_loss: 0.6821 - val_accuracy: 0.8815\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 2s 80ms/step - loss: 3.3289e-04 - accuracy: 1.0000 - val_loss: 0.7156 - val_accuracy: 0.8818\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 2s 78ms/step - loss: 2.5166e-04 - accuracy: 1.0000 - val_loss: 0.7294 - val_accuracy: 0.8802\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(512, activation=\"relu\"),\n",
    "    layers.Dense(512, activation=\"relu\"),\n",
    "    layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "history_larger_model = model.fit(\n",
    "    train_data, train_labels,\n",
    "    epochs=20, batch_size=512, validation_split=0.4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Adding weight regularization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Adding L2 weight regularization to the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30/30 [==============================] - 1s 29ms/step - loss: 0.6374 - accuracy: 0.7643 - val_loss: 0.5038 - val_accuracy: 0.8666\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.4352 - accuracy: 0.8880 - val_loss: 0.4109 - val_accuracy: 0.8800\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.3525 - accuracy: 0.9100 - val_loss: 0.3931 - val_accuracy: 0.8733\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.3163 - accuracy: 0.9186 - val_loss: 0.3607 - val_accuracy: 0.8885\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.2895 - accuracy: 0.9287 - val_loss: 0.3585 - val_accuracy: 0.8884\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.2703 - accuracy: 0.9352 - val_loss: 0.4005 - val_accuracy: 0.8670\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.2646 - accuracy: 0.9361 - val_loss: 0.3618 - val_accuracy: 0.8848\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.2504 - accuracy: 0.9437 - val_loss: 0.3677 - val_accuracy: 0.8839\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.2469 - accuracy: 0.9443 - val_loss: 0.3845 - val_accuracy: 0.8767\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.2398 - accuracy: 0.9477 - val_loss: 0.3707 - val_accuracy: 0.8834\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.2275 - accuracy: 0.9523 - val_loss: 0.4059 - val_accuracy: 0.8676\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.2286 - accuracy: 0.9511 - val_loss: 0.3904 - val_accuracy: 0.8773\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.2249 - accuracy: 0.9537 - val_loss: 0.3829 - val_accuracy: 0.8802\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.2167 - accuracy: 0.9571 - val_loss: 0.3830 - val_accuracy: 0.8809\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.2136 - accuracy: 0.9585 - val_loss: 0.3877 - val_accuracy: 0.8802\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.2178 - accuracy: 0.9535 - val_loss: 0.3989 - val_accuracy: 0.8764\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.2103 - accuracy: 0.9588 - val_loss: 0.4003 - val_accuracy: 0.8778\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.2014 - accuracy: 0.9625 - val_loss: 0.4245 - val_accuracy: 0.8705\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.2070 - accuracy: 0.9583 - val_loss: 0.4064 - val_accuracy: 0.8767\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.2010 - accuracy: 0.9616 - val_loss: 0.4031 - val_accuracy: 0.8782\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(16,\n",
    "                 kernel_regularizer=regularizers.l2(0.002), # L2 正则化\n",
    "                 activation=\"relu\"),\n",
    "    layers.Dense(16,\n",
    "                 kernel_regularizer=regularizers.l2(0.002),\n",
    "                 activation=\"relu\"),\n",
    "    layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "history_l2_reg = model.fit(\n",
    "    train_data, train_labels,\n",
    "    epochs=20, batch_size=512, validation_split=0.4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Different weight regularizers available in Keras**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.regularizers.L1L2 at 0x25082789ee0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "regularizers.l1(0.001)\n",
    "regularizers.l1_l2(l1=0.001, l2=0.001)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Adding dropout"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Adding dropout to the IMDB model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30/30 [==============================] - 1s 24ms/step - loss: 0.6510 - accuracy: 0.6283 - val_loss: 0.5768 - val_accuracy: 0.6701\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 1s 18ms/step - loss: 0.5538 - accuracy: 0.7810 - val_loss: 0.5015 - val_accuracy: 0.8252\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.4924 - accuracy: 0.8496 - val_loss: 0.4609 - val_accuracy: 0.8713\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 0s 17ms/step - loss: 0.4444 - accuracy: 0.8868 - val_loss: 0.4372 - val_accuracy: 0.8612\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.4023 - accuracy: 0.9022 - val_loss: 0.4100 - val_accuracy: 0.8825\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.3674 - accuracy: 0.9187 - val_loss: 0.4024 - val_accuracy: 0.8781\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.3391 - accuracy: 0.9268 - val_loss: 0.4079 - val_accuracy: 0.8748\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 0s 17ms/step - loss: 0.3112 - accuracy: 0.9355 - val_loss: 0.3989 - val_accuracy: 0.8787\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.2839 - accuracy: 0.9433 - val_loss: 0.3984 - val_accuracy: 0.8774\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.2619 - accuracy: 0.9468 - val_loss: 0.4571 - val_accuracy: 0.8656\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 0s 17ms/step - loss: 0.2352 - accuracy: 0.9527 - val_loss: 0.4129 - val_accuracy: 0.8763\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.2156 - accuracy: 0.9571 - val_loss: 0.4093 - val_accuracy: 0.8775\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.1988 - accuracy: 0.9595 - val_loss: 0.4036 - val_accuracy: 0.8769\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.1892 - accuracy: 0.9591 - val_loss: 0.4455 - val_accuracy: 0.8743\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.1702 - accuracy: 0.9663 - val_loss: 0.5029 - val_accuracy: 0.8718\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.1600 - accuracy: 0.9663 - val_loss: 0.5048 - val_accuracy: 0.8703\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.1495 - accuracy: 0.9679 - val_loss: 0.4974 - val_accuracy: 0.8739\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.1382 - accuracy: 0.9701 - val_loss: 0.4844 - val_accuracy: 0.8766\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 0s 17ms/step - loss: 0.1299 - accuracy: 0.9725 - val_loss: 0.6345 - val_accuracy: 0.8659\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.1243 - accuracy: 0.9719 - val_loss: 0.5777 - val_accuracy: 0.8728\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(16, activation=\"relu\"),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(16, activation=\"relu\"),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "history_dropout = model.fit(\n",
    "    train_data, train_labels,\n",
    "    epochs=20, batch_size=512, validation_split=0.4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Summary"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "chapter05_fundamentals-of-ml.i",
   "private_outputs": false,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
