{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "This is a companion notebook for the book [Deep Learning with Python, Second Edition](https://www.manning.com/books/deep-learning-with-python-second-edition?a_aid=keras&a_bid=76564dff). For readability, it only contains runnable code blocks and section titles, and omits everything else in the book: text paragraphs, figures, and pseudocode.\n",
    "\n",
    "**If you want to be able to follow what's going on, I recommend reading the notebook side by side with your copy of the book.**\n",
    "\n",
    "This notebook was generated for TensorFlow 2.6."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "# Working with Keras: A deep dive"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## A spectrum of workflows"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Different ways to build Keras models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### The Sequential model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**The `Sequential` class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Incrementally building a Sequential model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(layers.Dense(64, activation=\"relu\"))\n",
    "model.add(layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Calling a model for the first time to build it**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'dense_2/kernel:0' shape=(3, 64) dtype=float32, numpy=\n",
       " array([[-2.92311341e-01,  7.76692331e-02, -1.45095125e-01,\n",
       "          8.08590353e-02,  7.50843883e-02,  2.57834792e-03,\n",
       "         -4.34973836e-02,  2.83728182e-01,  2.78947055e-01,\n",
       "         -2.21459001e-01, -2.81680018e-01, -2.11366192e-01,\n",
       "         -1.96302384e-01, -9.88183320e-02, -1.86735988e-01,\n",
       "         -2.73884088e-01,  2.80391097e-01, -1.89496785e-01,\n",
       "          1.78966045e-01, -2.46986538e-01,  2.08946943e-01,\n",
       "         -2.07035750e-01,  1.82524562e-01, -8.54557753e-03,\n",
       "         -4.09292281e-02, -3.38074863e-02, -2.39768386e-01,\n",
       "          2.48676538e-02, -2.01462880e-01,  1.47596866e-01,\n",
       "          2.80369580e-01, -2.45911255e-01, -2.13826597e-01,\n",
       "          1.21921301e-04, -2.35520720e-01,  8.66411924e-02,\n",
       "         -2.52021104e-01,  2.08408833e-02,  1.92611575e-01,\n",
       "         -2.64653087e-01,  2.01863706e-01,  5.86984456e-02,\n",
       "         -1.18272141e-01, -2.43154824e-01,  6.02801442e-02,\n",
       "         -1.20574519e-01,  2.65279531e-01, -2.38235265e-01,\n",
       "          1.48084313e-01, -1.35911793e-01,  4.85288799e-02,\n",
       "         -4.89349067e-02,  1.17700368e-01, -1.91734433e-01,\n",
       "          1.56310946e-01, -2.61504441e-01, -2.84147769e-01,\n",
       "          1.05592132e-01,  1.32396489e-01, -2.74067461e-01,\n",
       "          1.06982321e-01,  3.41525972e-02, -2.81255066e-01,\n",
       "          1.20729327e-01],\n",
       "        [ 3.28110456e-02, -2.64303118e-01, -2.59267062e-01,\n",
       "         -2.81998932e-01, -6.56962097e-02, -2.84660965e-01,\n",
       "          4.32672203e-02, -4.50529754e-02,  2.98807919e-02,\n",
       "         -1.01545021e-01, -2.67875433e-01,  1.69283330e-01,\n",
       "          6.80456758e-02, -1.20107472e-01, -1.67036176e-01,\n",
       "         -1.53987736e-01,  2.66307294e-01,  4.37371135e-02,\n",
       "          8.50610435e-02,  2.92580545e-01,  1.01965904e-01,\n",
       "          2.34906554e-01,  2.30939627e-01, -6.78505450e-02,\n",
       "          1.74118131e-01, -1.75812483e-01, -2.14018956e-01,\n",
       "          6.10829592e-02,  1.04729116e-01, -5.94567358e-02,\n",
       "         -1.10725999e-01,  1.55710757e-01, -5.61061502e-03,\n",
       "         -1.56439513e-01, -3.34627926e-02, -2.96089977e-01,\n",
       "         -1.90838188e-01,  5.12049198e-02, -1.15221739e-01,\n",
       "          2.66873002e-01,  8.86610150e-02,  9.85639095e-02,\n",
       "         -7.80177116e-03,  2.64857411e-01,  1.97370261e-01,\n",
       "          2.61964738e-01, -1.71669766e-01, -2.28382558e-01,\n",
       "          2.70402610e-01, -1.88225359e-01,  1.95127785e-01,\n",
       "         -1.13251850e-01, -2.18429014e-01, -1.98400006e-01,\n",
       "         -9.27654356e-02,  3.83703709e-02,  4.36692536e-02,\n",
       "          2.23939240e-01, -1.06033191e-01,  4.88457978e-02,\n",
       "          7.16764927e-02,  1.59125745e-01, -2.53097147e-01,\n",
       "         -1.34795561e-01],\n",
       "        [ 2.96066701e-01, -2.18006283e-01, -2.91345030e-01,\n",
       "          6.65795803e-02, -2.36934960e-01,  2.57476509e-01,\n",
       "          1.52333826e-01, -1.46504939e-02,  1.96867824e-01,\n",
       "          3.96496356e-02,  7.48825371e-02,  7.08760321e-02,\n",
       "          1.53328121e-01, -2.66100168e-01,  1.20299399e-01,\n",
       "         -2.27384865e-02,  1.65870219e-01, -1.82341635e-01,\n",
       "         -2.74016380e-01,  2.07637548e-02, -1.49273157e-01,\n",
       "          2.74221182e-01,  1.72423691e-01, -1.24504551e-01,\n",
       "          1.53334826e-01,  7.70202279e-03, -6.86733276e-02,\n",
       "         -1.00522816e-01,  1.21434540e-01,  2.89445221e-01,\n",
       "          1.53866649e-01,  8.04494917e-02, -1.23784438e-01,\n",
       "          7.13616610e-04,  2.45034456e-01, -1.65682852e-01,\n",
       "         -3.15921307e-02,  2.42546320e-01,  7.58170485e-02,\n",
       "          6.97068572e-02,  9.28886533e-02,  1.72136366e-01,\n",
       "         -2.88296044e-01,  5.96786141e-02,  6.21182024e-02,\n",
       "         -2.84003943e-01, -2.07490325e-02,  2.13312447e-01,\n",
       "         -1.17202923e-01,  1.21445745e-01, -2.32597262e-01,\n",
       "         -3.51937711e-02,  1.61175698e-01,  2.88593411e-01,\n",
       "          2.24360764e-01,  1.72129452e-01,  2.50598073e-01,\n",
       "          7.66785741e-02, -1.58769861e-01, -2.58652776e-01,\n",
       "          8.75053406e-02,  1.19779915e-01, -1.01586580e-02,\n",
       "          1.39354438e-01]], dtype=float32)>,\n",
       " <tf.Variable 'dense_2/bias:0' shape=(64,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n",
       " <tf.Variable 'dense_3/kernel:0' shape=(64, 10) dtype=float32, numpy=\n",
       " array([[-4.11686748e-02, -2.30536133e-01, -4.91814911e-02,\n",
       "          8.04714859e-02, -2.63442248e-01, -2.24744648e-01,\n",
       "         -2.49263465e-01, -1.99592173e-01,  1.21648103e-01,\n",
       "          1.80051237e-01],\n",
       "        [ 2.73016363e-01, -4.30812538e-02, -1.72394514e-01,\n",
       "         -2.24666655e-01, -9.32965577e-02, -1.82387784e-01,\n",
       "          1.51753724e-01,  1.20954841e-01,  2.56834418e-01,\n",
       "          1.65939152e-01],\n",
       "        [-2.42877632e-01,  1.32731467e-01,  1.54933780e-01,\n",
       "         -2.52081752e-01,  3.58962715e-02,  1.12977445e-01,\n",
       "         -2.48966798e-01, -4.08306569e-02,  5.89175224e-02,\n",
       "          2.21395820e-01],\n",
       "        [ 1.23046696e-01, -2.62515068e-01, -8.31015855e-02,\n",
       "          1.48099363e-02, -1.68919474e-01, -1.06024534e-01,\n",
       "          1.08191282e-01,  1.40127510e-01,  2.39818245e-01,\n",
       "         -1.77580222e-01],\n",
       "        [-1.55524686e-01, -5.87017089e-02,  1.56792521e-01,\n",
       "         -2.34253734e-01, -3.74181420e-02, -1.83036268e-01,\n",
       "         -2.75761992e-01,  1.42811865e-01, -1.72534093e-01,\n",
       "          1.47330135e-01],\n",
       "        [-3.18034589e-02, -2.33037233e-01, -2.64110327e-01,\n",
       "          2.18067855e-01,  1.17053181e-01, -1.34731010e-01,\n",
       "          1.01318598e-01, -6.40419126e-03, -1.91034079e-01,\n",
       "          2.78966635e-01],\n",
       "        [-1.47134349e-01,  6.71733916e-02, -2.56606072e-01,\n",
       "         -1.24370188e-01, -1.85649723e-01, -1.90194219e-01,\n",
       "         -8.36352557e-02,  1.40891671e-01,  2.33279079e-01,\n",
       "          5.17727435e-02],\n",
       "        [ 1.53430372e-01, -2.23708391e-01, -4.97585535e-03,\n",
       "         -2.81505823e-01, -1.39432058e-01, -2.45046467e-01,\n",
       "          2.50941962e-01, -6.51278198e-02, -6.58903420e-02,\n",
       "          2.10740566e-01],\n",
       "        [ 6.78905547e-02, -1.56105489e-01,  2.37538606e-01,\n",
       "         -3.19011509e-02,  7.40742385e-02,  2.62126595e-01,\n",
       "         -1.93976998e-01, -2.77974725e-01, -2.04094633e-01,\n",
       "         -2.57118434e-01],\n",
       "        [-1.20748997e-01,  1.90699905e-01, -6.03276491e-02,\n",
       "          2.93064117e-02,  8.35455656e-02, -8.37584138e-02,\n",
       "          1.59929544e-01, -2.47823685e-01,  1.43711239e-01,\n",
       "         -2.18289018e-01],\n",
       "        [-2.32638121e-02,  5.72127700e-02, -1.14676312e-01,\n",
       "          7.44934678e-02,  1.93192005e-01,  1.85203135e-01,\n",
       "          1.21251225e-01, -1.05916992e-01, -1.65784225e-01,\n",
       "          2.07866490e-01],\n",
       "        [-1.51297510e-01, -1.80844799e-01, -2.79776156e-01,\n",
       "         -1.30226776e-01,  7.00710118e-02,  5.29091358e-02,\n",
       "          2.58690149e-01,  7.03920722e-02, -3.13490629e-03,\n",
       "         -1.28873676e-01],\n",
       "        [-2.06307620e-01, -1.18808791e-01,  1.17089421e-01,\n",
       "         -2.15892330e-01,  4.61655855e-02, -1.46739364e-01,\n",
       "          1.06982648e-01, -8.20543319e-02, -7.98585266e-02,\n",
       "          1.19252712e-01],\n",
       "        [-1.37960777e-01,  2.31901854e-01, -2.45951772e-01,\n",
       "          7.20161796e-02,  2.47632772e-01, -3.82450372e-02,\n",
       "         -2.24544659e-01,  1.96243614e-01, -1.23946697e-01,\n",
       "          1.44750208e-01],\n",
       "        [ 1.03867501e-01, -1.52797997e-01, -8.78983587e-02,\n",
       "          8.84653032e-02,  2.12607592e-01, -4.69660014e-02,\n",
       "          2.83885747e-01, -7.76110590e-02, -1.62032127e-01,\n",
       "         -1.52146593e-01],\n",
       "        [-1.45642698e-01, -1.69188246e-01, -1.49477422e-02,\n",
       "         -1.08200982e-01,  1.25601232e-01,  4.70291972e-02,\n",
       "         -1.24033943e-01,  1.88352853e-01, -1.59305036e-02,\n",
       "         -1.64039195e-01],\n",
       "        [ 9.95039344e-02, -2.75489986e-01, -1.92213088e-01,\n",
       "          1.17923111e-01,  2.59637207e-01,  2.17391819e-01,\n",
       "          1.51031733e-01,  1.69616073e-01,  2.78041214e-01,\n",
       "         -2.53642738e-01],\n",
       "        [-2.83575356e-01, -4.57837731e-02, -2.54425079e-01,\n",
       "         -6.74511194e-02,  2.45868772e-01, -1.82315484e-01,\n",
       "          7.27109611e-02,  1.92430288e-01,  1.09137505e-01,\n",
       "          6.76054358e-02],\n",
       "        [ 2.23809779e-02, -9.66926366e-02, -8.51601362e-03,\n",
       "         -1.92167878e-01, -5.50327152e-02,  7.78965354e-02,\n",
       "         -7.36437589e-02, -2.11404592e-01, -1.64891139e-01,\n",
       "         -1.96478769e-01],\n",
       "        [ 2.52695769e-01, -1.38892412e-01,  1.02680653e-01,\n",
       "         -2.10445657e-01, -8.14784914e-02,  1.18086517e-01,\n",
       "          2.53914803e-01,  2.77240783e-01,  7.46594369e-02,\n",
       "          2.57800668e-01],\n",
       "        [-2.81488776e-01, -2.19297111e-01, -7.76938051e-02,\n",
       "          1.36125654e-01,  2.43529826e-01,  1.86160862e-01,\n",
       "          1.94727093e-01,  2.66173035e-01, -1.54104725e-01,\n",
       "          2.24410623e-01],\n",
       "        [-9.58646536e-02,  1.51218832e-01, -2.82679796e-02,\n",
       "         -5.96652627e-02,  2.40132898e-01, -2.78843224e-01,\n",
       "         -1.97863027e-01, -1.90272763e-01,  9.66589749e-02,\n",
       "          2.00217426e-01],\n",
       "        [-1.59945488e-01,  2.65201032e-02,  2.56314874e-03,\n",
       "         -2.84412295e-01, -1.93014741e-03,  2.67734081e-01,\n",
       "         -2.84579217e-01,  5.07273376e-02, -1.15703344e-02,\n",
       "         -2.66334981e-01],\n",
       "        [-2.57558823e-02,  8.59591365e-03, -1.65975094e-02,\n",
       "         -2.07508370e-01,  1.18095815e-01,  2.74056166e-01,\n",
       "          2.61447281e-01, -1.25844479e-02,  1.24756426e-01,\n",
       "          1.77223474e-01],\n",
       "        [-7.17586130e-02,  1.59507751e-01,  9.80914235e-02,\n",
       "          2.50545144e-02,  1.34295702e-01, -4.29427624e-02,\n",
       "          1.20439947e-01, -9.78233218e-02, -1.74178436e-01,\n",
       "          1.48881555e-01],\n",
       "        [ 7.06990659e-02, -2.48498321e-02,  2.53215581e-01,\n",
       "          5.57518005e-03,  1.88507766e-01,  2.21251518e-01,\n",
       "          1.29941374e-01, -8.50391388e-03, -1.32698953e-01,\n",
       "         -2.81590134e-01],\n",
       "        [ 1.63663507e-01, -3.50388885e-03,  2.44567543e-01,\n",
       "         -2.75231987e-01,  2.45697469e-01,  2.42624849e-01,\n",
       "         -5.10872006e-02,  1.60167962e-01, -1.94916129e-03,\n",
       "          1.07116878e-01],\n",
       "        [ 7.44677782e-02, -2.09541589e-01,  2.37170368e-01,\n",
       "         -7.88867474e-04,  2.06989080e-01, -2.68651843e-01,\n",
       "         -2.53128678e-01,  5.75534403e-02,  1.85558617e-01,\n",
       "          2.48306006e-01],\n",
       "        [-5.69139123e-02, -1.31712675e-01, -2.13880837e-01,\n",
       "         -7.99377561e-02,  1.79257959e-01, -7.18979836e-02,\n",
       "          1.83279306e-01, -2.50783652e-01, -2.16083303e-01,\n",
       "          1.40979648e-01],\n",
       "        [ 2.52821356e-01, -3.71364802e-02, -1.33961439e-02,\n",
       "         -8.57079029e-03,  1.99243009e-01,  1.51976526e-01,\n",
       "         -1.74850732e-01,  2.62385875e-01, -2.75861949e-01,\n",
       "          9.87202823e-02],\n",
       "        [-1.90501511e-02, -2.64902264e-01, -1.99785307e-01,\n",
       "         -2.75657117e-01, -6.93655163e-02, -7.56510943e-02,\n",
       "         -3.85401547e-02, -1.06582716e-01,  1.57093078e-01,\n",
       "          2.75540352e-03],\n",
       "        [ 2.34226197e-01, -2.79116333e-01,  2.34726638e-01,\n",
       "         -2.23616481e-01,  2.56156534e-01, -2.22944111e-01,\n",
       "         -2.74668992e-01,  2.30340272e-01,  1.74279034e-01,\n",
       "          1.56977028e-01],\n",
       "        [ 2.27862507e-01,  6.41869307e-02, -1.67065829e-01,\n",
       "          4.99311984e-02,  1.45290405e-01,  2.34943420e-01,\n",
       "         -4.80220765e-02,  2.42535084e-01,  1.34277344e-03,\n",
       "         -2.48901904e-01],\n",
       "        [-8.96153301e-02, -4.87873256e-02,  2.22405821e-01,\n",
       "          8.77732337e-02, -2.13415116e-01, -1.67961568e-01,\n",
       "         -2.35831007e-01,  1.04511201e-01,  2.09389091e-01,\n",
       "         -9.66529846e-02],\n",
       "        [ 3.77717912e-02, -1.94293901e-01,  2.68906742e-01,\n",
       "         -2.28280991e-01,  8.60124528e-02,  2.27497905e-01,\n",
       "          2.28592902e-01, -8.89110565e-02,  1.21946335e-02,\n",
       "         -1.03000209e-01],\n",
       "        [-2.15131164e-01,  2.77474970e-01, -5.42484522e-02,\n",
       "          8.01843405e-03, -2.37395510e-01,  2.66676217e-01,\n",
       "          2.27174073e-01, -3.95766795e-02,  2.03248531e-01,\n",
       "         -5.11312634e-02],\n",
       "        [ 2.36332417e-05, -2.83468157e-01, -2.62370139e-01,\n",
       "         -8.12463164e-02,  1.00612640e-03,  1.10788375e-01,\n",
       "         -5.97620010e-02, -9.95069742e-03, -7.20598400e-02,\n",
       "          2.58523852e-01],\n",
       "        [ 1.23090684e-01, -1.98145211e-02, -2.26408958e-01,\n",
       "          7.52968490e-02,  3.82192433e-02,  4.37945724e-02,\n",
       "          2.84375995e-01,  1.96163148e-01,  5.33090830e-02,\n",
       "          2.44522363e-01],\n",
       "        [-1.46492124e-01,  1.02306247e-01, -1.58656001e-01,\n",
       "          2.49777585e-01,  2.21379131e-01,  9.49233770e-04,\n",
       "         -1.67930603e-01, -2.71478534e-01, -2.79717416e-01,\n",
       "          2.75189430e-01],\n",
       "        [-2.30701715e-01, -2.03573182e-01,  4.78805304e-02,\n",
       "          4.39653099e-02, -9.73675251e-02,  1.51625425e-01,\n",
       "         -2.54861951e-01,  2.75284022e-01,  2.60760486e-02,\n",
       "         -5.92026561e-02],\n",
       "        [ 2.45035142e-01, -2.45551974e-01,  1.60816699e-01,\n",
       "          1.77085727e-01, -2.82175541e-02,  9.52607989e-02,\n",
       "         -5.11939973e-02,  8.24212730e-02, -1.32941738e-01,\n",
       "          1.22916698e-02],\n",
       "        [ 6.94938898e-02,  2.34231353e-03, -5.69263101e-03,\n",
       "         -1.92951560e-02, -1.77771196e-01, -1.89856678e-01,\n",
       "          2.21093088e-01, -1.41831473e-01,  7.81053603e-02,\n",
       "         -1.77513212e-01],\n",
       "        [-2.09471583e-02,  1.50321871e-01, -2.37048462e-01,\n",
       "          5.97347915e-02, -2.73832530e-01, -9.07830298e-02,\n",
       "         -2.31985629e-01, -2.02152133e-03, -1.13015339e-01,\n",
       "          2.74801522e-01],\n",
       "        [ 1.26722068e-01,  2.06619561e-01, -6.75718933e-02,\n",
       "          1.52341574e-01, -1.45970732e-01,  3.39358449e-02,\n",
       "          1.18402004e-01,  7.76959062e-02, -9.38054472e-02,\n",
       "          2.06631035e-01],\n",
       "        [ 6.74774647e-02,  1.63301378e-01,  2.02966034e-01,\n",
       "         -8.51419866e-02,  1.26382977e-01,  1.10748529e-01,\n",
       "         -7.91979581e-02,  1.52960718e-02, -2.68187016e-01,\n",
       "         -7.55120665e-02],\n",
       "        [ 3.27117443e-02,  2.21186668e-01, -9.84877646e-02,\n",
       "          2.06286430e-01,  1.73757106e-01, -1.54888302e-01,\n",
       "         -2.63336807e-01, -1.42869949e-02,  1.97075248e-01,\n",
       "         -6.28764182e-02],\n",
       "        [ 1.30377024e-01,  5.12564480e-02,  4.44272161e-02,\n",
       "          1.08174294e-01, -3.61463875e-02, -4.28127497e-02,\n",
       "         -1.03579298e-01,  1.43785864e-01, -6.44874871e-02,\n",
       "         -2.07644761e-01],\n",
       "        [ 7.28976429e-02, -1.81584865e-01, -1.95856631e-01,\n",
       "          1.48396283e-01,  2.54745990e-01,  2.50692576e-01,\n",
       "         -1.74933225e-01,  7.58684874e-02,  2.34101206e-01,\n",
       "          2.82603770e-01],\n",
       "        [-1.76652670e-02, -1.53551087e-01, -1.36632726e-01,\n",
       "          1.47964835e-01,  2.67436892e-01,  8.48650038e-02,\n",
       "         -2.76469946e-01, -4.25397009e-02,  6.13713861e-02,\n",
       "          1.38205111e-01],\n",
       "        [-1.90181375e-01,  9.06541646e-02, -2.20093727e-02,\n",
       "          1.13982767e-01,  5.41296601e-02, -9.39614624e-02,\n",
       "          1.79753631e-01,  1.85222954e-01, -2.68817008e-01,\n",
       "         -2.06206664e-01],\n",
       "        [-7.69586414e-02,  1.42440498e-01,  2.80043572e-01,\n",
       "         -2.34460264e-01, -2.44190663e-01,  2.11248577e-01,\n",
       "          1.80455804e-01, -2.17157915e-01, -9.91847813e-02,\n",
       "          6.94435239e-02],\n",
       "        [-1.53651968e-01,  2.66553670e-01, -1.22749612e-01,\n",
       "         -4.80269045e-02, -2.54284561e-01, -9.75436866e-02,\n",
       "         -2.60002226e-01,  2.57880479e-01, -6.46007955e-02,\n",
       "          1.44729584e-01],\n",
       "        [ 1.97194457e-01,  2.57166535e-01, -1.63769811e-01,\n",
       "         -2.43875086e-02, -1.58018127e-01,  4.91288006e-02,\n",
       "          1.85239196e-01,  1.27145022e-01, -1.71871021e-01,\n",
       "         -1.98258966e-01],\n",
       "        [ 6.63107634e-03, -7.14656711e-02, -6.29924983e-02,\n",
       "          2.14770526e-01,  2.83895046e-01, -8.01994652e-02,\n",
       "          1.98435754e-01,  1.65668279e-01,  8.05145204e-02,\n",
       "          1.56869650e-01],\n",
       "        [-2.43722767e-01,  1.36615545e-01, -1.66167110e-01,\n",
       "         -1.51755422e-01,  1.83899730e-01,  1.36205375e-01,\n",
       "         -2.81678319e-01, -1.19003221e-01,  1.19505346e-01,\n",
       "         -2.58842677e-01],\n",
       "        [-8.22957456e-02,  2.08979398e-01, -2.60145754e-01,\n",
       "          1.12806916e-01, -1.33175537e-01,  1.08416796e-01,\n",
       "         -2.19496220e-01, -5.16220927e-03,  1.70656085e-01,\n",
       "         -4.79165763e-02],\n",
       "        [ 2.21190363e-01,  1.98214978e-01,  2.80097425e-02,\n",
       "         -9.23712254e-02, -2.14029849e-02, -9.43008363e-02,\n",
       "          1.34855241e-01,  6.83668852e-02,  1.75585091e-01,\n",
       "          1.63334459e-01],\n",
       "        [ 1.18074834e-01, -2.70468146e-01,  2.83194929e-01,\n",
       "         -3.84037644e-02, -8.55811685e-02, -1.64024681e-01,\n",
       "         -1.85477823e-01, -1.54289514e-01,  2.26513594e-01,\n",
       "         -6.13118410e-02],\n",
       "        [ 2.61120230e-01,  1.49388254e-01,  1.71039999e-01,\n",
       "          1.54486477e-01,  1.87630713e-01, -3.55255306e-02,\n",
       "          2.11369842e-01,  1.35124922e-02,  2.31312543e-01,\n",
       "          5.58332503e-02],\n",
       "        [-2.76323229e-01, -2.29348823e-01, -2.61686414e-01,\n",
       "         -1.79229110e-01,  2.07407296e-01,  2.17199355e-01,\n",
       "         -7.57063627e-02,  1.70426130e-01, -1.41192019e-01,\n",
       "         -4.33652252e-02],\n",
       "        [ 2.21624225e-01, -1.34959668e-01,  2.74553597e-02,\n",
       "         -1.33676693e-01, -2.50255048e-01, -1.66046888e-01,\n",
       "         -2.53544480e-01, -2.56207377e-01,  5.24170697e-02,\n",
       "          5.52652180e-02],\n",
       "        [-8.45565796e-02,  9.31763947e-02,  1.29226446e-01,\n",
       "         -1.62025064e-01, -1.79990962e-01, -2.48024091e-01,\n",
       "         -1.52596503e-01,  1.89971805e-01, -1.87086105e-01,\n",
       "         -7.19374269e-02],\n",
       "        [ 2.19241887e-01,  1.49265468e-01,  6.43321574e-02,\n",
       "         -2.04834223e-01,  3.78396809e-02, -2.19130158e-01,\n",
       "          2.47521490e-01, -7.48519003e-02,  5.32095432e-02,\n",
       "          2.30534822e-01],\n",
       "        [-1.50357246e-01,  1.17016524e-01, -1.00803524e-01,\n",
       "         -2.35906780e-01,  1.86211437e-01, -2.13840187e-01,\n",
       "          2.38581687e-01, -1.89362496e-01, -5.34540862e-02,\n",
       "          4.89248037e-02]], dtype=float32)>,\n",
       " <tf.Variable 'dense_3/bias:0' shape=(10,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.build(input_shape=(None, 3))\n",
    "model.weights"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**The summary method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2 (Dense)             (None, 64)                256       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 906\n",
      "Trainable params: 906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary() # 展示模型的架构"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Naming models and layers with the `name` argument**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_example_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " my_first_layer (Dense)      (None, 64)                256       \n",
      "                                                                 \n",
      " my_last_layer (Dense)       (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 906\n",
      "Trainable params: 906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential(name=\"my_example_model\")\n",
    "model.add(layers.Dense(64, activation=\"relu\", name=\"my_first_layer\"))\n",
    "model.add(layers.Dense(10, activation=\"softmax\", name=\"my_last_layer\"))\n",
    "model.build((None, 3))\n",
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Specifying the input shape of your model in advance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.Input(shape=(3,)))\n",
    "model.add(layers.Dense(64, activation=\"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_4 (Dense)             (None, 64)                256       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 256\n",
      "Trainable params: 256\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_4 (Dense)             (None, 64)                256       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 906\n",
      "Trainable params: 906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.add(layers.Dense(10, activation=\"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### The Functional API"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### A simple example"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**A simple Functional model with two `Dense` layers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(3,), name=\"my_input\")\n",
    "features = layers.Dense(64, activation=\"relu\")(inputs)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# inputs对象保存了关于模型将处理的数据的形状和数据类型的信息\n",
    "inputs = keras.Input(shape=(3,), name=\"my_input\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 3])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.float32"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "features = layers.Dense(64, activation=\"relu\")(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 64])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "# 在Model构造函数中指定输入和输出，将模型实例化\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " my_input (InputLayer)       [(None, 3)]               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 64)                256       \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 906\n",
      "Trainable params: 906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Multi-input, multi-output models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**A multi-input, multi-output Functional model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "vocabulary_size = 10000\n",
    "num_tags = 100\n",
    "num_departments = 4\n",
    "\n",
    "title = keras.Input(shape=(vocabulary_size,), name=\"title\")\n",
    "text_body = keras.Input(shape=(vocabulary_size,), name=\"text_body\")\n",
    "tags = keras.Input(shape=(num_tags,), name=\"tags\")\n",
    "\n",
    "features = layers.Concatenate()([title, text_body, tags])\n",
    "features = layers.Dense(64, activation=\"relu\")(features)\n",
    "\n",
    "priority = layers.Dense(1, activation=\"sigmoid\", name=\"priority\")(features)\n",
    "department = layers.Dense(\n",
    "    num_departments, activation=\"softmax\", name=\"department\")(features)\n",
    "\n",
    "model = keras.Model(inputs=[title, text_body, tags], outputs=[priority, department])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " title (InputLayer)             [(None, 10000)]      0           []                               \n",
      "                                                                                                  \n",
      " text_body (InputLayer)         [(None, 10000)]      0           []                               \n",
      "                                                                                                  \n",
      " tags (InputLayer)              [(None, 100)]        0           []                               \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 20100)        0           ['title[0][0]',                  \n",
      "                                                                  'text_body[0][0]',              \n",
      "                                                                  'tags[0][0]']                   \n",
      "                                                                                                  \n",
      " dense_10 (Dense)               (None, 64)           1286464     ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " priority (Dense)               (None, 1)            65          ['dense_10[0][0]']               \n",
      "                                                                                                  \n",
      " department (Dense)             (None, 4)            260         ['dense_10[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,286,789\n",
      "Trainable params: 1,286,789\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Training a multi-input, multi-output model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Training a model by providing lists of input & target arrays**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 1s 13ms/step - loss: 48.9735 - priority_loss: 0.3219 - department_loss: 48.6516 - priority_mean_absolute_error: 0.4892 - department_accuracy: 0.1445\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 30.9314 - priority_loss: 0.3340 - department_loss: 30.5974 - priority_mean_absolute_error: 0.5019 - department_accuracy: 0.0602\n",
      "40/40 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "num_samples = 1280\n",
    "\n",
    "title_data = np.random.randint(0, 2, size=(num_samples, vocabulary_size))\n",
    "text_body_data = np.random.randint(0, 2, size=(num_samples, vocabulary_size))\n",
    "tags_data = np.random.randint(0, 2, size=(num_samples, num_tags))\n",
    "\n",
    "priority_data = np.random.random(size=(num_samples, 1))\n",
    "department_data = np.random.randint(0, 2, size=(num_samples, num_departments))\n",
    "\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=[\"mean_squared_error\", \"categorical_crossentropy\"],\n",
    "              metrics=[[\"mean_absolute_error\"], [\"accuracy\"]])\n",
    "model.fit([title_data, text_body_data, tags_data],\n",
    "          [priority_data, department_data],\n",
    "          epochs=1)\n",
    "model.evaluate([title_data, text_body_data, tags_data],\n",
    "               [priority_data, department_data])\n",
    "priority_preds, department_preds = model.predict([title_data, text_body_data, tags_data])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Training a model by providing dicts of input & target arrays**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 1s 14ms/step - loss: 40.5699 - priority_loss: 0.3340 - department_loss: 40.2359 - priority_mean_absolute_error: 0.5019 - department_accuracy: 0.2156\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 37.6389 - priority_loss: 0.3340 - department_loss: 37.3049 - priority_mean_absolute_error: 0.5019 - department_accuracy: 0.1117\n",
      "40/40 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss={\"priority\": \"mean_squared_error\", \"department\": \"categorical_crossentropy\"},\n",
    "              metrics={\"priority\": [\"mean_absolute_error\"], \"department\": [\"accuracy\"]})\n",
    "model.fit({\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data},\n",
    "          {\"priority\": priority_data, \"department\": department_data},\n",
    "          epochs=1)\n",
    "model.evaluate({\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data},\n",
    "               {\"priority\": priority_data, \"department\": department_data})\n",
    "priority_preds, department_preds = model.predict(\n",
    "    {\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### The power of the Functional API: Access to layer connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "keras.utils.plot_model(model, \"ticket_classifier.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "keras.utils.plot_model(model, \"ticket_classifier_with_shape_info.png\", show_shapes=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Retrieving the inputs or outputs of a layer in a Functional model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.input_layer.InputLayer at 0x244bbcb0970>,\n",
       " <keras.engine.input_layer.InputLayer at 0x244bbcb09d0>,\n",
       " <keras.engine.input_layer.InputLayer at 0x244bbcb0cd0>,\n",
       " <keras.layers.merging.concatenate.Concatenate at 0x244bbcb30d0>,\n",
       " <keras.layers.core.dense.Dense at 0x244bbca8f10>,\n",
       " <keras.layers.core.dense.Dense at 0x244bbca8d60>,\n",
       " <keras.layers.core.dense.Dense at 0x244bbcb3910>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<KerasTensor: shape=(None, 10000) dtype=float32 (created by layer 'title')>,\n",
       " <KerasTensor: shape=(None, 10000) dtype=float32 (created by layer 'text_body')>,\n",
       " <KerasTensor: shape=(None, 100) dtype=float32 (created by layer 'tags')>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[3].input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 20100) dtype=float32 (created by layer 'concatenate')>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[3].output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Creating a new model by reusing intermediate layer outputs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "features = model.layers[4].output\n",
    "difficulty = layers.Dense(3, activation=\"softmax\", name=\"difficulty\")(features)\n",
    "\n",
    "new_model = keras.Model(\n",
    "    inputs=[title, text_body, tags],\n",
    "    outputs=[priority, department, difficulty])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "keras.utils.plot_model(new_model, \"updated_ticket_classifier.png\", show_shapes=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Subclassing the Model class"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Rewriting our previous example as a subclassed model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**A simple subclassed model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "class CustomerTicketModel(keras.Model):\n",
    "\n",
    "    def __init__(self, num_departments):\n",
    "        super().__init__()\n",
    "        self.concat_layer = layers.Concatenate()\n",
    "        self.mixing_layer = layers.Dense(64, activation=\"relu\")\n",
    "        self.priority_scorer = layers.Dense(1, activation=\"sigmoid\")\n",
    "        self.department_classifier = layers.Dense(\n",
    "            num_departments, activation=\"softmax\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        title = inputs[\"title\"]\n",
    "        text_body = inputs[\"text_body\"]\n",
    "        tags = inputs[\"tags\"]\n",
    "\n",
    "        features = self.concat_layer([title, text_body, tags])\n",
    "        features = self.mixing_layer(features)\n",
    "        priority = self.priority_scorer(features)\n",
    "        department = self.department_classifier(features)\n",
    "        return priority, department"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = CustomerTicketModel(num_departments=4)\n",
    "\n",
    "priority, department = model(\n",
    "    {\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 1s 14ms/step - loss: 27.9726 - output_1_loss: 0.3230 - output_2_loss: 27.6496 - output_1_mean_absolute_error: 0.4909 - output_2_accuracy: 0.3156\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 11.8214 - output_1_loss: 0.3301 - output_2_loss: 11.4913 - output_1_mean_absolute_error: 0.4981 - output_2_accuracy: 0.1320\n",
      "40/40 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=[\"mean_squared_error\", \"categorical_crossentropy\"],\n",
    "              metrics=[[\"mean_absolute_error\"], [\"accuracy\"]])\n",
    "model.fit({\"title\": title_data,\n",
    "           \"text_body\": text_body_data,\n",
    "           \"tags\": tags_data},\n",
    "          [priority_data, department_data],\n",
    "          epochs=1)\n",
    "model.evaluate({\"title\": title_data,\n",
    "                \"text_body\": text_body_data,\n",
    "                \"tags\": tags_data},\n",
    "               [priority_data, department_data])\n",
    "priority_preds, department_preds = model.predict({\"title\": title_data,\n",
    "                                                  \"text_body\": text_body_data,\n",
    "                                                  \"tags\": tags_data})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Beware: What subclassed models don't support"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Mixing and matching different components"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Creating a Functional model that includes a subclassed model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "class Classifier(keras.Model):\n",
    "\n",
    "    def __init__(self, num_classes=2):\n",
    "        super().__init__()\n",
    "        if num_classes == 2:\n",
    "            num_units = 1\n",
    "            activation = \"sigmoid\"\n",
    "        else:\n",
    "            num_units = num_classes\n",
    "            activation = \"softmax\"\n",
    "        self.dense = layers.Dense(num_units, activation=activation)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.dense(inputs)\n",
    "\n",
    "inputs = keras.Input(shape=(3,))\n",
    "features = layers.Dense(64, activation=\"relu\")(inputs)\n",
    "outputs = Classifier(num_classes=10)(features)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Creating a subclassed model that includes a Functional model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(64,))\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(inputs)\n",
    "binary_classifier = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "class MyModel(keras.Model):\n",
    "\n",
    "    def __init__(self, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.dense = layers.Dense(64, activation=\"relu\")\n",
    "        self.classifier = binary_classifier\n",
    "\n",
    "    def call(self, inputs):\n",
    "        features = self.dense(inputs)\n",
    "        return self.classifier(features)\n",
    "\n",
    "model = MyModel()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Remember: Use the right tool for the job"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Using built-in training and evaluation loops"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**The standard workflow: `compile()`, `fit()`, `evaluate()`, `predict()`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.2930 - accuracy: 0.9132 - val_loss: 0.1490 - val_accuracy: 0.9562\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1569 - accuracy: 0.9552 - val_loss: 0.1176 - val_accuracy: 0.9681\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1312 - accuracy: 0.9621 - val_loss: 0.1059 - val_accuracy: 0.9713\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0939 - accuracy: 0.9749\n",
      "313/313 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "def get_mnist_model():\n",
    "    inputs = keras.Input(shape=(28 * 28,))\n",
    "    features = layers.Dense(512, activation=\"relu\")(inputs)\n",
    "    features = layers.Dropout(0.5)(features)\n",
    "    outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "(images, labels), (test_images, test_labels) = mnist.load_data()\n",
    "images = images.reshape((60000, 28 * 28)).astype(\"float32\") / 255\n",
    "test_images = test_images.reshape((10000, 28 * 28)).astype(\"float32\") / 255\n",
    "train_images, val_images = images[10000:], images[:10000]\n",
    "train_labels, val_labels = labels[10000:], labels[:10000]\n",
    "\n",
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=3,\n",
    "          validation_data=(val_images, val_labels))\n",
    "test_metrics = model.evaluate(test_images, test_labels)\n",
    "predictions = model.predict(test_images)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Writing your own metrics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Implementing a custom metric by subclassing the `Metric` class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class RootMeanSquaredError(keras.metrics.Metric):\n",
    "\n",
    "    def __init__(self, name=\"rmse\", **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.mse_sum = self.add_weight(name=\"mse_sum\", initializer=\"zeros\")\n",
    "        self.total_samples = self.add_weight(\n",
    "            name=\"total_samples\", initializer=\"zeros\", dtype=\"int32\")\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_true = tf.one_hot(y_true, depth=tf.shape(y_pred)[1])\n",
    "        mse = tf.reduce_sum(tf.square(y_true - y_pred))\n",
    "        self.mse_sum.assign_add(mse)\n",
    "        num_samples = tf.shape(y_pred)[0]\n",
    "        self.total_samples.assign_add(num_samples)\n",
    "\n",
    "    def result(self):\n",
    "        return tf.sqrt(self.mse_sum / tf.cast(self.total_samples, tf.float32))\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.mse_sum.assign(0.)\n",
    "        self.total_samples.assign(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1563/1563 [==============================] - 9s 5ms/step - loss: 0.2941 - accuracy: 0.9125 - rmse: 7.1762 - val_loss: 0.1543 - val_accuracy: 0.9553 - val_rmse: 7.3474\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1601 - accuracy: 0.9543 - rmse: 7.3471 - val_loss: 0.1198 - val_accuracy: 0.9666 - val_rmse: 7.4015\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1286 - accuracy: 0.9635 - rmse: 7.3833 - val_loss: 0.1125 - val_accuracy: 0.9702 - val_rmse: 7.4243\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1051 - accuracy: 0.9722 - rmse: 7.4384\n"
     ]
    }
   ],
   "source": [
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\", RootMeanSquaredError()])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=3,\n",
    "          validation_data=(val_images, val_labels))\n",
    "test_metrics = model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Using callbacks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### The EarlyStopping and ModelCheckpoint callbacks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Using the `callbacks` argument in the `fit()` method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.2938 - accuracy: 0.9129 - val_loss: 0.1458 - val_accuracy: 0.9567\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 0.1572 - accuracy: 0.9538 - val_loss: 0.1206 - val_accuracy: 0.9663\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1318 - accuracy: 0.9622 - val_loss: 0.1035 - val_accuracy: 0.9712\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1115 - accuracy: 0.9681 - val_loss: 0.0986 - val_accuracy: 0.9741\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1019 - accuracy: 0.9709 - val_loss: 0.0937 - val_accuracy: 0.9765\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0922 - accuracy: 0.9743 - val_loss: 0.0959 - val_accuracy: 0.9767\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0870 - accuracy: 0.9762 - val_loss: 0.0960 - val_accuracy: 0.9772\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0816 - accuracy: 0.9778 - val_loss: 0.0922 - val_accuracy: 0.9794\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0765 - accuracy: 0.9795 - val_loss: 0.0862 - val_accuracy: 0.9792\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0750 - accuracy: 0.9795 - val_loss: 0.0929 - val_accuracy: 0.9789\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x244c5cc6970>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callbacks_list = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_accuracy\",\n",
    "        patience=2,\n",
    "    ),\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"checkpoint_path.keras\",\n",
    "        monitor=\"val_loss\",\n",
    "        save_best_only=True,\n",
    "    )\n",
    "]\n",
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=10,\n",
    "          callbacks=callbacks_list,\n",
    "          validation_data=(val_images, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"checkpoint_path.keras\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Writing your own callbacks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Creating a custom callback by subclassing the `Callback` class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs):\n",
    "        # 在训练开始时\n",
    "        self.per_batch_losses = []\n",
    "\n",
    "    def on_batch_end(self, batch, logs):\n",
    "        # 在每个批次结束时\n",
    "        self.per_batch_losses.append(logs.get(\"loss\"))\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        # 在每个周期结束时\n",
    "        plt.clf()\n",
    "        plt.plot(range(len(self.per_batch_losses)), self.per_batch_losses,\n",
    "                 label=\"Training loss for each batch\")\n",
    "        plt.xlabel(f\"Batch (epoch {epoch})\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.legend()\n",
    "        plt.savefig(f\"plot_at_epoch_{epoch}\")\n",
    "        self.per_batch_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.2929 - accuracy: 0.9128 - val_loss: 0.1483 - val_accuracy: 0.9587\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1571 - accuracy: 0.9544 - val_loss: 0.1104 - val_accuracy: 0.9703\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1268 - accuracy: 0.9639 - val_loss: 0.1039 - val_accuracy: 0.9729\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1121 - accuracy: 0.9680 - val_loss: 0.0896 - val_accuracy: 0.9752\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1011 - accuracy: 0.9724 - val_loss: 0.0947 - val_accuracy: 0.9761\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0956 - accuracy: 0.9745 - val_loss: 0.0920 - val_accuracy: 0.9772\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0855 - accuracy: 0.9760 - val_loss: 0.0904 - val_accuracy: 0.9790\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0838 - accuracy: 0.9784 - val_loss: 0.0882 - val_accuracy: 0.9797\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0748 - accuracy: 0.9798 - val_loss: 0.0880 - val_accuracy: 0.9804\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0729 - accuracy: 0.9807 - val_loss: 0.0935 - val_accuracy: 0.9790\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x244cbff8fa0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=10,\n",
    "          callbacks=[LossHistory()],\n",
    "          validation_data=(val_images, val_labels))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Monitoring and visualization with TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 9s 5ms/step - loss: 0.2962 - accuracy: 0.9120 - val_loss: 0.1399 - val_accuracy: 0.9590\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1601 - accuracy: 0.9532 - val_loss: 0.1168 - val_accuracy: 0.9669\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1281 - accuracy: 0.9637 - val_loss: 0.1057 - val_accuracy: 0.9700\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1125 - accuracy: 0.9690 - val_loss: 0.1025 - val_accuracy: 0.9726\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1009 - accuracy: 0.9721 - val_loss: 0.0950 - val_accuracy: 0.9751\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0910 - accuracy: 0.9744 - val_loss: 0.0970 - val_accuracy: 0.9747\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 9s 5ms/step - loss: 0.0866 - accuracy: 0.9760 - val_loss: 0.0993 - val_accuracy: 0.9775\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0804 - accuracy: 0.9785 - val_loss: 0.1000 - val_accuracy: 0.9777\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0744 - accuracy: 0.9798 - val_loss: 0.0949 - val_accuracy: 0.9785\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0724 - accuracy: 0.9796 - val_loss: 0.0962 - val_accuracy: 0.9794\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x244c5264670>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "tensorboard = keras.callbacks.TensorBoard(\n",
    "    log_dir=\"/full_path_to_your_log_dir\",\n",
    ")\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=10,\n",
    "          validation_data=(val_images, val_labels),\n",
    "          callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-bdc0d503ca4524a4\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-bdc0d503ca4524a4\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %load_ext tensorboard\n",
    "%tensorboard --logdir /full_path_to_your_log_dir"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Writing your own training and evaluation loops"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Training versus inference"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Low-level usage of metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: 1.00\n"
     ]
    }
   ],
   "source": [
    "metric = keras.metrics.SparseCategoricalAccuracy()\n",
    "targets = [0, 1, 2]\n",
    "predictions = [[1, 0, 0], [0, 1, 0], [0, 0, 1]]\n",
    "metric.update_state(targets, predictions)\n",
    "current_result = metric.result()\n",
    "print(f\"result: {current_result:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of values: 2.00\n"
     ]
    }
   ],
   "source": [
    "values = [0, 1, 2, 3, 4]\n",
    "mean_tracker = keras.metrics.Mean()\n",
    "for value in values:\n",
    "    mean_tracker.update_state(value)\n",
    "print(f\"Mean of values: {mean_tracker.result():.2f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### A complete training and evaluation loop"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Writing a step-by-step training loop: the training step function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = get_mnist_model()\n",
    "\n",
    "loss_fn = keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = keras.optimizers.RMSprop()\n",
    "metrics = [keras.metrics.SparseCategoricalAccuracy()]\n",
    "loss_tracking_metric = keras.metrics.Mean()\n",
    "\n",
    "def train_step(inputs, targets):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(inputs, training=True)\n",
    "        loss = loss_fn(targets, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
    "\n",
    "    logs = {}\n",
    "    for metric in metrics:\n",
    "        metric.update_state(targets, predictions)\n",
    "        logs[metric.name] = metric.result()\n",
    "\n",
    "    loss_tracking_metric.update_state(loss)\n",
    "    logs[\"loss\"] = loss_tracking_metric.result()\n",
    "    return logs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Writing a step-by-step training loop: resetting the metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "def reset_metrics():\n",
    "    for metric in metrics:\n",
    "        metric.reset_state()\n",
    "    loss_tracking_metric.reset_state()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Writing a step-by-step training loop: the loop itself**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results at the end of epoch 0\n",
      "...sparse_categorical_accuracy: 0.9156\n",
      "...loss: 0.2875\n",
      "Results at the end of epoch 1\n",
      "...sparse_categorical_accuracy: 0.9543\n",
      "...loss: 0.1609\n",
      "Results at the end of epoch 2\n",
      "...sparse_categorical_accuracy: 0.9642\n",
      "...loss: 0.1300\n"
     ]
    }
   ],
   "source": [
    "training_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
    "training_dataset = training_dataset.batch(32)\n",
    "epochs = 3\n",
    "for epoch in range(epochs):\n",
    "    reset_metrics()\n",
    "    for inputs_batch, targets_batch in training_dataset:\n",
    "        logs = train_step(inputs_batch, targets_batch)\n",
    "    print(f\"Results at the end of epoch {epoch}\")\n",
    "    for key, value in logs.items():\n",
    "        print(f\"...{key}: {value:.4f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Writing a step-by-step evaluation loop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results:\n",
      "...val_sparse_categorical_accuracy: 0.9672\n",
      "...val_loss: 0.1231\n"
     ]
    }
   ],
   "source": [
    "def test_step(inputs, targets):\n",
    "    predictions = model(inputs, training=False)\n",
    "    loss = loss_fn(targets, predictions)\n",
    "\n",
    "    logs = {}\n",
    "    for metric in metrics:\n",
    "        metric.update_state(targets, predictions)\n",
    "        logs[\"val_\" + metric.name] = metric.result()\n",
    "\n",
    "    loss_tracking_metric.update_state(loss)\n",
    "    logs[\"val_loss\"] = loss_tracking_metric.result()\n",
    "    return logs\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels))\n",
    "val_dataset = val_dataset.batch(32)\n",
    "reset_metrics()\n",
    "for inputs_batch, targets_batch in val_dataset:\n",
    "    logs = test_step(inputs_batch, targets_batch)\n",
    "print(\"Evaluation results:\")\n",
    "for key, value in logs.items():\n",
    "    print(f\"...{key}: {value:.4f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Make it fast with tf.function"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Adding a `tf.function` decorator to our evaluation-step function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results:\n",
      "...val_sparse_categorical_accuracy: 0.9672\n",
      "...val_loss: 0.1231\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def test_step(inputs, targets):\n",
    "    predictions = model(inputs, training=False)\n",
    "    loss = loss_fn(targets, predictions)\n",
    "\n",
    "    logs = {}\n",
    "    for metric in metrics:\n",
    "        metric.update_state(targets, predictions)\n",
    "        logs[\"val_\" + metric.name] = metric.result()\n",
    "\n",
    "    loss_tracking_metric.update_state(loss)\n",
    "    logs[\"val_loss\"] = loss_tracking_metric.result()\n",
    "    return logs\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels))\n",
    "val_dataset = val_dataset.batch(32)\n",
    "reset_metrics()\n",
    "for inputs_batch, targets_batch in val_dataset:\n",
    "    logs = test_step(inputs_batch, targets_batch)\n",
    "print(\"Evaluation results:\")\n",
    "for key, value in logs.items():\n",
    "    print(f\"...{key}: {value:.4f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Leveraging fit() with a custom training loop"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Implementing a custom training step to use with `fit()`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "loss_fn = keras.losses.SparseCategoricalCrossentropy()\n",
    "loss_tracker = keras.metrics.Mean(name=\"loss\")\n",
    "\n",
    "class CustomModel(keras.Model):\n",
    "    def train_step(self, data):\n",
    "        inputs, targets = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self(inputs, training=True)\n",
    "            loss = loss_fn(targets, predictions)\n",
    "        gradients = tape.gradient(loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_weights))\n",
    "\n",
    "        loss_tracker.update_state(loss)\n",
    "        return {\"loss\": loss_tracker.result()}\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [loss_tracker]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 0.2934\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.1603\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.1297\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x244bc432b80>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(28 * 28,))\n",
    "features = layers.Dense(512, activation=\"relu\")(inputs)\n",
    "features = layers.Dropout(0.5)(features)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "model = CustomModel(inputs, outputs)\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.RMSprop())\n",
    "model.fit(train_images, train_labels, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "class CustomModel(keras.Model):\n",
    "    def train_step(self, data):\n",
    "        inputs, targets = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self(inputs, training=True)\n",
    "            loss = self.compiled_loss(targets, predictions)\n",
    "        gradients = tape.gradient(loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_weights))\n",
    "        self.compiled_metrics.update_state(targets, predictions)\n",
    "        return {m.name: m.result() for m in self.metrics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.2960 - sparse_categorical_accuracy: 0.9113\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 0.1590 - sparse_categorical_accuracy: 0.9538\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 0.1285 - sparse_categorical_accuracy: 0.9635\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x244bb150250>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(28 * 28,))\n",
    "features = layers.Dense(512, activation=\"relu\")(inputs)\n",
    "features = layers.Dropout(0.5)(features)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "model = CustomModel(inputs, outputs)\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.RMSprop(),\n",
    "              loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=[keras.metrics.SparseCategoricalAccuracy()])\n",
    "model.fit(train_images, train_labels, epochs=3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Summary"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "chapter07_working-with-keras.i",
   "private_outputs": false,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
